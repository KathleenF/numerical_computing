\lab{Algorithms}{Givens rotations}{Givens rotations}
\objective{Use orthogonal transformations to perform QR decomposition.}

In Lab \ref{lab:Canonical Transformations} we discussed how to form the QR decomposition of a matrix using a series of householder reflectors.
The general approach was to apply a series of orthogonal transformations to a given matrix to transform it into upper triangular form.
This same approach can be applied using rotations instead of reflections.

The matrix $\begin{pmatrix}\ cos \theta & - \sin \theta \\ \sin \theta & \cos \theta \end{pmatrix}$ rotates a vector counterclockwise by $\theta$.
Given a vector $x = \begin{pmatrix} a \\ b \end{pmatrix}$, we can rotate $x$ into the span of $e_1$ by choosing the correct $\theta$.
This zeros out the entry containing $b$.
We could do this by finding the angle between $\begin{pmatrix} a \\ b \end{pmatrix}$ and the axis containing $b$ then rotating the vector by the negative of that angle.
In order to avoid computations involving $\sin$ and $\arcsin$ at each iteration we can just solve for $\sin \theta $ and $\cos \theta$ using the pythagorean theorem instead of explicitly computing $\theta$.
Such an approach gives us the result that $\cos \theta = \frac{a}{\sqrt{a^2 + b^2}}$ and $\sin \theta = \frac{- b}{\sqrt{a^2 + b^2}}$.
The transformed image of $\begin{pmatrix} a \\ b \end{pmatrix}$ is then $\begin{pmatrix} \| \sqrt{a^2 + b^2} \| \\ 0 \end{pmatrix}$.

The application of such a rotation to any two rows of a matrix $A$ is an orthonormal transform.
Such a transformation can be represented in matrix form, where $c = \cos \theta$ and $s = \sin \theta$, like this:
\begin{equation*}
\begin{pmatrix}
I & 0 & 0 & 0 & 0 \\
0 & c & 0 & -s & 0 \\
0 & 0 & I & 0 & 0 \\
0 & s & 0 & c & 0 \\
0 & 0 & 0 & 0 & I
\end{pmatrix}
\end{equation*}
In actual computation, we \emph{do not} actually form such a large matrix at each step.
Instead we apply the transformation to the two rows we want to change and then leave the rest of the matrix unchanged.
Proceeding in this manner we can zero out each entry of any matrix below its main diagonal, resulting in a QR factorization.
For an example, consider some matrix $A$.
Let $G \left( i, j, k \right)$ denote the givens rotation that will zero out $A \left[ j, k \right]$ by rotation with row $i$ of $A$.
We can zero out the entries below the main diagonal of A as follows:

\[
\begin{array}{ccccccc}
\begin{pmatrix}
*&*&*\\
*&*&*\\
*&*&*
\end{pmatrix}
&
\underrightarrow{G(1,2,0)}
&\begin{pmatrix}
*&*&*\\
*&*&*\\
0&*&*
\end{pmatrix}
&
\underrightarrow{G(0,1,0)}
&\begin{pmatrix}
*&*&*\\
0&*&*\\
0&*&*
\end{pmatrix}
&
\underrightarrow{G(1,2,1)}
&\begin{pmatrix}
*&*&*\\
0&*&*\\
0&0&*
\end{pmatrix}
\end{array}
\]

Here is an outline for the algorithm.
Let $A$ be the array passed to the function.

\begin{itemize}[$\bullet$]

\item Make $R$ a copy of $A$ and $Q$ an identity array of the appropriate size.

\item Make an empty $2 \times 2$ array $G$ that will be used to apply the Givens rotations

\item For each column:

  \begin{itemize}[$\bullet$]

  \item For each row below the main diagonal (starting at the bottom of the column):

    \begin{itemize}[$\bullet$]

    \item If the leading entry of this row is not zero:

      \begin{itemize}[$\bullet$]

      \item Compute $c$ and $s$ using the entry in the current row and column and the entry immediately above it.

      \item Use $c$ and $s$ to construct the matrix $G$.

      \item Get a slice of $R$ of the current row and the row above it that includes the columns from the current column onward.
      Multiply it in place by $G$ to zero out the leading nonzero entry of the current row.

      \item Get a slice of $Q$ of the current row and the row above it and apply $G$ to it as well. (Strictly speaking, you do not need to operate over these entire rows, but the slicing needed to avoid the extra computation is a little more involved, so we will not include that here.)

      \end{itemize}

    \end{itemize}

  \end{itemize}

\item Return the transpose of $Q$ and $R$.

\end{itemize}

Because givens rotations only operate on two specific rows at a time, they give us a variety of ways to iterate over an array we are processing.
For example, using givens rotations you could, starting at the bottom of each column and continuing up until you reach the main diagonal, zero out each entry by applying a givens rotation to each row and the row immediately above it.
Alternatively, within each column, you could could zero out the first entry of each row below the main diagonal by rotating it with the row corresponding to the main diagonal.
Yet another way to do it would be to start at the bottom left corner of the matrix and then zero out each entry from left to right along each diagonal.
This flexibility is what makes the use of givens rotations ideal for some problems.
When working with sparse matrices, Givens rotations allow for the solution of linear systems through a series of orthonormal operations that operate only on small parts of the array.
The fact that Givens rotations operate only on small portions of the array also lends well to parallel solutions to systems of equations (or least squares problems).
They allow for the sort of flexibility we had when using Gaussian elimination while still maintaining the favorable stability that comes with using orthonormal transformations.

While Givens rotations do allow for greather flexibility and are well suited for parallelization, they also require a greater number of floating point operations than Householder reflections.
In general, the operation count for computing the QR factorization for an $m \times n$ matrix is $3 n^2 \left( m - \frac{n}{3} \right)$.
% Accuracy and Stability of Numerical Algorithms, Nicholas J. Higham
There are modified versions of the Givens QR algorithm that use "fast givens rotations" which decrease the number of multiplications and square roots needed for the application of each givens rotation.
% Fast Plane Rotations With Dynamic Scaling, Anda and Park, SIAM, 1994
It allows for the use of Givens rotations while requiring roughly the same number of floating point operations used by the Householder QR algorithm.
In practice, these methods are still not quite as fast as the Householder algorithm.
In spite of the need for more floating point operations, Givens rotations are still well suited for parallelization and can be much faster than the Householder algorithm when multiple processors are used.
% Givens and Householder Reductions for Linear Least Squares on a Cluster of Workstations, Omer Egecioglu and Ashok Srinivasan

\begin{problem}
Write a script that uses Givens rotations to compute the $QR$ decomposition of a matrix $A$.
By performing successive Givens rotations, triangularize $A$ to find $R$.
Apply the rotations to an identity matrix as you go, then take the transpose to invert it and find $Q$.
\end{problem}